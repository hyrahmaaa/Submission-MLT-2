# -*- coding: utf-8 -*-
"""Proyek_Sistem_Rekomendasi_Rahayu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yt8kMRsBTbxa0mon1WPrBzSvSh-amllG

# Proyek Analisis Sistem Rekomendasi: [Sistem Rekomendasi Film Indonesia Berbasis Data IMDB]
- **Nama:** Rahayu Nur Rahmawati
- **Email:** a229xbm406@devacademy.id
- **ID Dicoding:** A229XBM406

# Business Understanding

**PROBLEM STATEMENT**

Dengan semakin banyaknya pilihan film yang tersedia di berbagai platform streaming dan bioskop, pengguna seringkali kesulitan menemukan film yang sesuai dengan selera mereka. Hal ini dapat menyebabkan:

1. Waktu pencarian yang terbuang: Pengguna menghabiskan waktu terlalu banyak untuk mencari film tanpa hasil yang memuaskan.

2. Konten relevan terlewat: Pengguna melewatkan film-film berkualitas tinggi yang sebenarnya relevan dengan minat mereka.


**GOALS**

Untuk menjawab pertanyaan tersebut dan mengatasi permasalahan yang ada, proyek ini bertujuan untuk:

1. Mempercepat dan mempersonalisasi pencarian: Membangun model machine learning berbasis Content-Based Filtering yang mampu merekomendasikan film kepada pengguna berdasarkan kesamaan fitur film (genre dan aktor), sehingga mempercepat proses penemuan film yang relevan.

2. Meningkatkan penemuan konten relevan: Menganalisis dan memahami karakteristik serta preferensi film dari kumpulan data yang tersedia terutama berdasarkan user_rating untuk memastikan rekomendasi yang diberikan adalah film-film berkualitas tinggi dan sesuai dengan minat pengguna.


**METODOLOGI**

Proyek ini akan fokus pada pembangunan sistem rekomendasi film menggunakan metodologi Content-Based Filtering. Pendekatan ini dipilih karena efektivitasnya dalam merekomendasikan item berdasarkan atributnya.  Ini termasuk dalam taksononomi masuk kategori personalized. Metodologi yang akan diterapkan meliputi:

1. Pra-pemrosesan Data: Membersihkan dan mempersiapkan data film (judul, genre, sutradara, aktor, sinopsis, dll.) dari dataset Kaggle yang telah dipilih.

2. Ekstraksi Fitur: Mengubah fitur teks (seperti sinopsis, genre) menjadi representasi numerik menggunakan teknik seperti TF-IDF (Term Frequency-Inverse Document Frequency) atau Embedding.

3. Penghitungan Kesamaan: Mengukur tingkat kesamaan antar film berdasarkan fitur-fitur yang telah diekstraksi menggunakan metrik kesamaan seperti Cosine Similarity.

4. Generasi Rekomendasi: Menentukan film-film yang paling mirip dengan film yang disukai pengguna dan merekomendasikannya.


**METRIK**

Karena sistem rekomendasi content-based ini berfokus pada kesamaan fitur maka metrik evaluasi akan lebih berorientasi pada kualitas rekomendasi dan relevansi. Metrik yang digunakan adalah Top-N Accuracy dimana mengukur proporsi rekomendasi yang relevan di antara N rekomendasi teratas yang diberikan. Namun, ini dapat diukur secara kualitatif melalui sampling atau user testing. Dalam hal ini, dapat dinilai dari penulis.

Tujuan utama dari pengembangan model ini adalah untuk menghasilkan rekomendasi film yang relevan, beragam, dan menarik bagi pengguna, sehingga meningkatkan pengalaman mereka dalam menemukan film.


**DATA**

Pengembangan sistem rekomendasi film ini akan menggunakan dataset dari Kaggle yaitu: IMDB Indonesian Movies (tautan: https://www.kaggle.com/datasets/dionisiusdh/imdb-indonesian-movies). Dataset ini diharapkan mencakup informasi penting mengenai film-film Indonesia seperti:

- 'title' : Judul lengkap dari film, ini identifikasi utama sebuah film.
- 'year' : Tahun rilis film, menunjukkan kapan film tersebut pertama kali dipublikasikan atau ditayangkan.
- 'description' : Ringkasan atau sinopsis cerita film, ini sangat penting untuk content-based filtering karena menjelaskan isi film secara detail.
- 'genre' : Kategori atau jenis film berdasarkan tema, gaya, atau alur cerita.
- 'rating' : Klasifikasi usia penonton atau tingkat kedewasaan konten film. Ini menunjukkan batasan usia minimum yang disarankan untuk menonton film tersebut berdasarkan isi (kekerasan, bahasa, tema dewasa, dll.).
- 'user_rating' : Rata-rata penilaian yang diberikan pengguna (bukan kritikus profesional).
- 'votes' : Jumlah total suara atau penilaian yang berkontribusi pada 'rating' atau 'users rating' sebuah film. Menunjukkan seberapa banyak orang yang telah memberikan penilaian. Semakin tinggi jumlah 'votes', semakin representatif 'rating' tersebut.
- 'languages' : Bahasa utama yang digunakan dalam film.
- 'directors' : Nama sutradara yang mengarahkan film. Sutradara adalah elemen penting dalam identifikasi gaya dan kualitas film.
- 'actors' : Nama-nama aktor/aktris utama yang berperan dalam film. Kehadiran aktor tertentu bisa menjadi daya tarik bagi penonton.
- 'runtime' : Durasi atau lama waktu film dalam satuan menit.

Data ini akan menjadi dasar untuk mengekstrak fitur dan membangun model rekomendasi.

# Data Understanding

### Data Loading

Import Library yang digunakan
"""

import pandas as pd
import numpy as np
import ast
import re
import matplotlib.pyplot as plt
import seaborn as sns
import math
from fuzzywuzzy import process
from IPython.display import display
from google.colab import drive

"""Unggah Dataset"""

drive.mount('/content/gdrive/')

file_path = '/content/gdrive/MyDrive/LASKAR AI/SUBMISSION/indonesian_movies.csv'
df = pd.read_csv(file_path)
df.head()

df.shape

# Mendapatkan daftar nama kolom
labels = df.columns.tolist()
labels

"""### Exploratory Data Analysis - Deskripsi Variabel"""

# Cek informasi umum termasuk jenis variabel dataset
df.dtypes

"""Jika ditinjau jauh, kolom 'votes' dan 'runtime' seharusnya berupa int karena votes adalah jumlah dan runtime ini waktu (terdapat imbuhan min sehingga menjadi object, perlu dihapus). Selain itu, untuk kategori lebih baik 'year' menjadi object dibanding int."""

for column in df.columns:
    print(f"--- Kolom: '{column}' ---")

    # Menghitung jumlah nilai unik
    unique_count = df[column].nunique()
    print(f"Banyak nilai unik: {unique_count}")

    if unique_count <= 50:
        print(f"Nilai unik: {df[column].unique()}\n")
    else:
        print(f"Beberapa contoh nilai unik: {df[column].unique()[:20]}\n")

"""Diperoleh insight:
- Jika 'title' merupakan identitas film seharusnya 1272 unique value semua tetapi ternyata hanya 1262. perlu dicek duplikasinya.
- Jika 'year' memiliki 62 unique value kemungkinan besar tahun nya sangat jauh dari yang terbaru hingga yang terlama.
- Jika 'description' hanya memiliki 820 unique value, kemungkinan terdapat 432 nilai tanpa deskripsi. perlu dicek missing value karena ini penting jika memang tidak ada bisa diganti dengan string kosong ' '. Hal ini agar tidak mempengaruhi isi film.
- Jika 'genre' terdapat kolom berisi nilai nan, maka ini masuk ke dalam missing value sehingga  perlu ditangani bisa diganti string kosong ' ' atau 'unknown genre'.
- Jika 'rating' terdapat kolom berisi nilai nan, maka ini masuk ke dalam missing value sehingga  perlu ditangani bisa diganti string kosong ' ' atau 'unknown'.
- Jika 'actors' memiliki nilai unik 1266 perlu dicek untuk nilai lainnya apakah ada yang kosong atau memang ada yang sama. Selanjutnya, kolom ini kemungkinan besar berisi daftar aktor yang dipisahkan koma dalam format string (seperti terlihat di contoh : ["['Aktor1', 'Aktor2']"]). Oleh karena itu, perlu membersihkan format string ini (menghilangkan [], '', "), memisahkan nama-nama aktor, dan mengolahnya menjadi daftar individu untuk digabungkan ke profil konten.
- Jika 'runtime' terdapat missing value maka  perlu ditangani bisa diganti dengan nilai median.

### Statistik Deskriptif Sebelum Preprocessing
"""

# Statistik deskriptif
df.describe()

"""Jika diperhatikan, statistik deskriptif ini belum sepenuhnya lengkap karena ada beberapa kolom setelah data preparation yang diubah menjadi numerik.

### Cek Missing Value
"""

# Cek missing value dengan fungsi isnull()
df.isnull().sum()

"""Untuk 'description' dan 'genre', penanganan NaN dengan string kosong adalah langkah yang tepat karena mereka akan digunakan untuk text vectorization. Bisa diganti dengan string kosong atau keterangan.

Untuk 'rating', bisa diganti dengan string kosong atau keterangan.

Untuk 'runtime' bisa diganti dengan nilai mediannya.

# Data Preparation

### Mengubah Tipe Data yang Benar
"""

df['votes'] = df['votes'].astype(str)
df['votes'] = pd.to_numeric(df['votes'].str.replace(',', ''), errors='coerce')
df['votes'] = df['votes'].fillna(0).astype(int)

df['runtime'] = df['runtime'].fillna('').astype(str)
df['runtime'] = df['runtime'].astype(str).str.replace(' min', '', regex=False)
df['runtime'] = pd.to_numeric(df['runtime'], errors='coerce')
df['runtime'] = df['runtime'].fillna(0).astype(int)

df['year'] = df['year'].astype(str)

# Cek informasi umum termasuk jenis variabel dataset
df.dtypes

"""### Statistik Deskriptif Setelah Preprocessing"""

# Statistik deskriptif
df.describe()

"""Insight:
- Imputasi runtime: Pertimbangkan lagi untuk mengganti nilai 0 di runtime (yang berasal dari missing values) dengan median dari kolom runtime (sekitar 89 menit) atau nilai yang lebih realistis. Ini akan membuat fitur runtime lebih bermakna.
- Penanganan votes: Karena distribusi votes sangat skewed, saat menggunakan votes untuk mengurutkan atau menilai kualitas film, pertimbangkan untuk menggunakan log transformasi atau metrik seperti Weighted Rating untuk menstabilkan pengaruh film dengan votes sangat tinggi.
- Analisis Outlier: Mungkin ada baiknya melihat film-film dengan year yang sangat tua, users_rating sangat rendah/tinggi, atau votes sangat tinggi untuk memahami karakteristiknya lebih lanjut.

### Metode Weight untuk Votes
"""

# Hitung C (rata-rata rating dari semua film dalam dataset). C adalah mean() dari kolom 'users_rating'
C = df['users_rating'].mean()
print(f"Rata-rata users_rating keseluruhan dataset (C): {C:.2f}")

# 2. Tentukan m (minimum votes yang diperlukan agar film masuk perhitungan signifikan)
m = df['votes'].quantile(0.75)
print(f"Ambang batas minimum votes (m, quantile 0.75): {int(m)} votes")

# 3. Definisikan fungsi untuk menghitung Weighted Rating
def calculate_weighted_rating(row, C, m):
    v = row['votes']        # v = jumlah votes untuk film tersebut
    R = row['users_rating'] # R = users_rating (rata-rata rating) untuk film tersebut

    # Formula Weighted Rating: (v / (v + m)) * R + (m / (v + m)) * C
    # Kita tambahkan penanganan kasus v + m = 0 meskipun jarang jika m > 0
    if (v + m) == 0:
        return C
    return (v / (v + m)) * R + (m / (v + m)) * C

# 4. Terapkan fungsi ke setiap baris DataFrame untuk membuat kolom 'weighted_rating' baru
df['weighted_rating'] = df.apply(lambda row: calculate_weighted_rating(row, C, m), axis=1)

print("\nKolom 'weighted_rating' berhasil ditambahkan.")

# Tampilkan beberapa baris untuk membandingkan users_rating, votes, dan weighted_rating
print("\nContoh perbandingan users_rating, votes, dan weighted_rating:")
print(df[['title', 'users_rating', 'votes', 'weighted_rating']].sort_values(by='weighted_rating', ascending=False).head(10))

print("\nDetail statistik untuk 'weighted_rating':")
print(df['weighted_rating'].describe())

df

"""Skor kualitas film yang dihitung menggunakan formula 'Weighted Rating' (mirip dengan IMDb), yang mempertimbangkan users_rating dan jumlah votes untuk memberikan penilaian yang lebih kredibel dan stabil. Film dengan rating tinggi dari sedikit votes akan "ditarik" mendekati rata-rata global, sementara film dengan rating tinggi dari banyak votes akan mempertahankan ratingnya.

### Menangani Missing Value
"""

df['description'] = df['description'].fillna('')

df['genre'] = df['genre'].fillna('Unknown Genre')

df['directors'] = df['directors'].fillna('Unknown Directors')

df['rating'] = df['rating'].fillna('Unknown')

df['runtime'] = df['runtime'].replace(0, np.nan)
runtime_median = df['runtime'].median()
df['runtime'] = df['runtime'].fillna(runtime_median).astype(int)

# Cek missing value dengan fungsi isnull()
df.isnull().sum()

"""### Menangani Duplikasi"""

print("\n--- Penanganan Duplikasi Data ---")

# 1. Cek jumlah duplikasi berdasarkan semua kolom
initial_duplicates_all_cols = df.duplicated().sum()
print(f"Jumlah baris duplikat (semua kolom): {initial_duplicates_all_cols}")

if initial_duplicates_all_cols > 0:
    print("Menghapus duplikasi berdasarkan semua kolom...")
    df.drop_duplicates(inplace=True)
    print(f"Jumlah baris setelah menghapus duplikasi (semua kolom): {len(df)}")
else:
    print("Tidak ada duplikasi baris berdasarkan semua kolom.")

# 2. Cek duplikasi berdasarkan kolom 'title' saja
duplicates_by_title = df.duplicated(subset=['title']).sum()
print(f"\nJumlah baris duplikat (berdasarkan kolom 'title' saja): {duplicates_by_title}")

if duplicates_by_title > 0:
    print("Berikut adalah contoh duplikasi berdasarkan 'title' sebelum dihapus:")
    # Menampilkan duplikat tanpa menghapusnya terlebih dahulu
    duplicated_titles_df = df[df.duplicated(subset=['title'], keep=False)].sort_values(by='title')
    print(duplicated_titles_df)

    print("\nMenghapus duplikasi berdasarkan 'title', mempertahankan entri pertama...")
    df.drop_duplicates(subset=['title'], keep='first', inplace=True)
    print(f"Jumlah baris setelah menghapus duplikasi (berdasarkan 'title' saja): {len(df)}")
else:
    print("Tidak ada duplikasi berdasarkan kolom 'title' saja.")


print("\n--- Proses Duplikasi Selesai ---")
print(f"Jumlah total film setelah penanganan duplikasi: {len(df)}")

print("Membuat kolom 'unique_title' dengan format 'Judul (Tahun)'...\n")

# Menggabungkan kolom 'title' dan 'year' untuk membuat identifier unik
df['unique_title'] = df['title'] + ' (' + df['year'].astype(str) + ')'

print("Kolom 'unique_title' berhasil dibuat.")

# Cek apakah ada duplikasi di kolom 'unique_title' (seharusnya tidak ada jika title dan year unik)
duplicates_in_unique_title = df.duplicated(subset=['unique_title']).sum()
print(f"Jumlah duplikasi berdasarkan 'unique_title': {duplicates_in_unique_title}")

print("\nContoh beberapa film dengan 'unique_title':")
print(df[['title', 'year', 'unique_title']].head(10))

print("\nContoh film yang sebelumnya duplikat berdasarkan judul, sekarang unik:")
# Filter film-film yang sebelumnya kita tahu duplikat dari output Anda
sample_titles = ['Arini','Badai Pasti Berlalu','Beranak dalam Kubur','Jomblo',
                 'Kuntilanak 2','Malam Jumat Kiwon','Ratu Ilmu Hitam','Roman Picisan',
                 'Si Manis Jembatan Ancol','Surat Kecil Untuk Tuhan']
print(df[df['title'].isin(sample_titles)][['title', 'year', 'unique_title']].sort_values(by='title'))

# Mendapatkan daftar nama kolom
labels = df.columns.tolist()
labels

df['title'] = df['unique_title']
df.drop('unique_title', axis=1, inplace=True)

# Mendapatkan daftar nama kolom
labels = df.columns.tolist()
labels

"""### Menangani Kolom Actors"""

def final_clean_text_column_corrected(text):
    if pd.isna(text) or str(text).strip() == '':
        return []
    s = str(text).strip()
    s = re.sub(r"\[|\]|\'|\"|", "", s)
    s = re.sub(r"[^\w\s,]", "", s)
    s = re.sub(r'\s+', ' ', s).strip()

    items = s.split(',')

    cleaned_items = []
    for item in items:
        processed_item = item.strip().lower().replace(' ', '_')
        processed_item = processed_item.strip('_') #

        if processed_item:
            cleaned_items.append(processed_item)
    return cleaned_items

df['actors'] = df['actors'].apply(final_clean_text_column_corrected)
print(f"Tipe data dari elemen pertama di df['actors']: {type(df['actors'].iloc[0])}")
print("Contoh 5 baris pertama df['actors'] setelah diproses:")
print(df['actors'].head())

# Mendapatkan daftar nama kolom
labels = df.columns.tolist()
labels

"""### Univariate Analysis"""

# Daftar Kolom Numerik
numerical_cols = [
    'users_rating',
    'votes',
    'runtime',
    'weighted_rating'
]

# Daftar Kolom Kategorikal (termasuk teks bebas)
categorical_cols = [
    'title',
    'year',
    'description',
    'genre',
    'rating',
    'languages',
    'directors',
    'actors'
]

print("Kolom Numerik:", numerical_cols)
print("Kolom Kategorikal:", categorical_cols)

df.hist(bins=50, figsize=(20,15))
plt.show()

"""Kolom yang lain cenderung berdistribusi normal. Namun untuk kolom 'votes' histogramnya adalah yang paling mencolok karena menunjukkan distribusi yang sangat ekstrem (highly skewed). Mayoritas film memiliki jumlah votes yang sangat sedikit (terkonsentrasi di dekat 0), sementara hanya segelintir film yang memiliki votes puluhan hingga ratusan ribu."""

# Definisi kolom kategorikal yang cocok untuk bar chart
plot_categorical_cols = [
    'year',
    'genre',
    'rating',
    'languages',
    'directors',
    'actors'
]

# Kolom yang akan dilewati dari pembuatan bar chart karena terlalu banyak kategori unik
skip_categorical_cols = ['title', 'description']

# Tentukan layout subplot
n_cols_per_row = 4
n_rows = math.ceil(len(plot_categorical_cols) / n_cols_per_row)
fig, axes = plt.subplots(n_rows, n_cols_per_row, figsize=(n_cols_per_row * 6, n_rows * 5), dpi=100)
axes = axes.flatten()

for i, col in enumerate(plot_categorical_cols):
    ax = axes[i]

    if col in ['genre', 'directors', 'actors']:
        all_items = [item for sublist in df[col].dropna() for item in sublist]
        value_counts_data = pd.Series(all_items).value_counts()
    else:
        value_counts_data = df[col].value_counts()

    if len(value_counts_data) > 30:
        plot_data = value_counts_data.head(30)
        ax.set_title(f'Distribusi {col} (Top 30)', fontsize=12)
    else:
        plot_data = value_counts_data
        ax.set_title(f'Distribusi {col}', fontsize=12)

    sns.barplot(x=plot_data.index, y=plot_data.values, palette='viridis', ax=ax)
    ax.set_xlabel(col, fontsize=10)
    ax.set_ylabel('Jumlah Film', fontsize=10)
    ax.tick_params(axis='x', rotation=45, labelsize=8)
    ax.tick_params(axis='y', labelsize=8)


for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0, 1, 0.98])
plt.suptitle('Distribusi Kolom Kategorikal', y=1.00, fontsize=16)
plt.show()

print("\n--- Visualisasi Bar Chart Kategorikal Selesai ---")
print("Catatan: Kolom 'title' dan 'description' tidak dibuatkan bar chart karena memiliki terlalu banyak kategori unik.")

"""Visualisasi sudah cukup jelas mulai dari 'year' terbanyak 2019, 'rating' terbanyak tidak diketahui, 'languages' terbanyak Indonesian. Namun untuk 'genre','directions' dan actors'diwakili dengan abjad namun dapat menunjukkan visual terbanyak hingga yang sedikit.

### Multivariate Analysis
"""

sns.pairplot(df, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_cols].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, ) # Changed df to data
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

# Tentukan layout subplot (misal, 2 kolom per baris)
n_cols_per_row = 2
n_rows = math.ceil(len(numerical_cols) / n_cols_per_row)

fig, axes = plt.subplots(n_rows, n_cols_per_row, figsize=(n_cols_per_row * 7, n_rows * 6), dpi=100)
axes = axes.flatten() # Meratakan array axes untuk iterasi mudah

# Iterasi melalui kolom-kolom numerik dan gambar boxplot
for i, col in enumerate(numerical_cols):
    sns.boxplot(y=df[col], ax=axes[i], palette='viridis')
    axes[i].set_title(f'Boxplot of {col}', fontsize=14)
    axes[i].set_ylabel(col, fontsize=12)
    axes[i].tick_params(axis='y', labelsize=10) # Atur ukuran label Y axis

# Sembunyikan subplot yang tidak terpakai jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0, 1, 0.98]) # Menyesuaikan layout
plt.suptitle('Boxplot Distribusi Kolom Numerik', y=1.00, fontsize=16) # Judul utama
plt.show()

"""# Modelling Berdasarkan Genre

### TF-IDF Vectorizer

Berdasarkan pertimbangan pada analisis sebelumnya, akan dilakukan sistem rekomendasi dengan 3 kolom saja yaitu title, genre, dan weighted_rating.
"""

df_new = df[['title','genre','weighted_rating']]
df_new

print("Jumlah data title adalah ", len(df_new.title.unique()))
print("Jumlah data genre adalah ", len(df_new.genre.unique()))
print("Jumlah data weighted_rating adalah ", len(df_new.weighted_rating.unique()))

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer()

# Melakukan perhitungan idf pada data teks
tfidf_matrix = tfidf_vectorizer.fit_transform(df_new['genre'])

# Mendapatkan daftar kata kunci (fitur) yang dihasilkan
feature_names = tfidf_vectorizer.get_feature_names_out()

print(feature_names)

# Melakukan fit lalu ditransformasikan ke bentuk matriks
tfidf_matrix = tf.fit_transform(df_new['genre'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf_vectorizer.get_feature_names_out(),
    index=df_new.title
).sample(18, axis=1).sample(10, axis=0)

"""### Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
genre_sim = cosine_similarity(tfidf_matrix)
genre_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama film
genre_sim_df = pd.DataFrame(genre_sim, index=df_new['title'], columns=df_new['title'])
print('Shape:', genre_sim_df.shape)

# Melihat similarity matrix pada setiap judul
genre_sim_df.sample(10, axis=1).sample(10, axis=0)

"""# Modelling Berdasarkan Actors

### TF-IDF Vectorizer

Berdasarkan pertimbangan pada analisis sebelumnya, akan dilakukan sistem rekomendasi dengan 3 kolom saja yaitu title, genre, dan weighted_rating.
"""

df_new1 = df[['title','actors','weighted_rating']]
df_new1

from sklearn.feature_extraction.text import TfidfVectorizer

df_new1['actors'] = df_new1['actors'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')

# Inisialisasi TfidfVectorizer
tfidf_vectorizer1 = TfidfVectorizer()

# Melakukan perhitungan idf pada data teks
tfidf_matrix1 = tfidf_vectorizer1.fit_transform(df_new1['actors'])

# Mendapatkan daftar kata kunci (fitur) yang dihasilkan
feature_names1 = tfidf_vectorizer1.get_feature_names_out()

print(feature_names1)

# Melakukan fit lalu ditransformasikan ke bentuk matriks
tfidf_matrix1 = tf.fit_transform(df_new1['actors'])

# Melihat ukuran matrix tfidf
tfidf_matrix1.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix1.todense()

# Membuat dataframe untuk melihat tf-idf matrix

pd.DataFrame(
    tfidf_matrix1.todense(),
    columns=tfidf_vectorizer1.get_feature_names_out(),
    index=df_new1.title
).sample(18, axis=1).sample(10, axis=0)

"""### Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
actor_sim = cosine_similarity(tfidf_matrix1)
actor_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama film
actor_sim_df = pd.DataFrame(genre_sim1, index=df_new1['title'], columns=df_new1['title'])
print('Shape:', actor_sim_df.shape)

# Melihat similarity matrix pada setiap judul
actor_sim_df.sample(10, axis=1).sample(10, axis=0)

"""# Evaluation

###  Berdasarkan Genre
"""

def film_recommendations(input_film, similarity_data = genre_sim_df, items = df_new[['title','genre','weighted_rating']], k=5):

    index = similarity_data.loc[:,input_film].to_numpy().argpartition(range(-1,-k,-1))

    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(input_film, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

df_new[df_new.title.eq('Milea (2020)')]

film_recommendations('Milea (2020)')

"""###  Berdasarkan Actors"""

def get_movies_by_actor(actor_name, df, top_n=10):
    if 'actors' not in df.columns or not all(isinstance(x, list) or pd.isna(x) for x in df['actors']):
         print("Error internal: Kolom 'actors' tidak dalam format list of strings yang diharapkan.")
         print("Mohon pastikan kode pemrosesan 'actors' sudah dijalankan dengan benar sebelum menjalankan fungsi ini.")
         return pd.DataFrame()

    search_actor_clean = actor_name.strip().lower().replace(' ', '_')
    movies_with_actor = df[df['actors'].apply(lambda x: search_actor_clean in x if isinstance(x, list) else False)]

    recommended_movies = movies_with_actor

    if recommended_movies.empty:
        print(f"Tidak ada film yang ditemukan dibintangi oleh '{actor_name}'.")
        print("Mencoba pencarian fuzzy matching...")
        all_unique_actors = []
        for sublist in df['actors'].dropna():
            all_unique_actors.extend(sublist)
        unique_actors_series = pd.Series(all_unique_actors).drop_duplicates()

        matches = process.extractOne(search_actor_clean, unique_actors_series)
        if matches and matches[1] > 80:
            print(f"Mungkin maksud Anda '{matches[0]}' (skor kecocokan: {matches[1]})?")

            return get_movies_by_actor(matches[0], df, top_n)
        else:
            print("Tidak ada kecocokan aktor yang dekat ditemukan.")
            return pd.DataFrame()


    if 'weighted_rating' not in recommended_movies.columns:
        print("Kolom 'weighted_rating' tidak ditemukan. Tidak dapat mengurutkan rekomendasi.")

        cols_to_select_no_rating = ['title', 'genre', 'directors', 'actors']
        existing_cols_no_rating = [col for col in cols_to_select_no_rating if col in recommended_movies.columns]
        return recommended_movies[existing_cols_no_rating].head(top_n)


    recommended_movies = recommended_movies.sort_values(by='weighted_rating', ascending=False)
    cols_to_select = ['title','actors', 'weighted_rating']

    existing_cols = [col for col in cols_to_select if col in recommended_movies.columns]
    return recommended_movies[existing_cols].head(top_n)

actor_1 = "adipati_dolken"
print(f"\nFilm yang dibintangi '{actor_1}':")
result_1 = get_movies_by_actor(actor_1, df)
if not result_1.empty:
    display(result_1)
